{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AK_g1ExA0sx7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import json\n",
        "import pandas as pd\n",
        "import gzip\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UGV7zzWBO5a",
        "outputId": "261530df-0c46-4b51-8861-61c8b3e307db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load Data from JSON File\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "\n",
        "df = getDF('AMAZON_FASHION_5.json.gz')\n",
        "df = df[df[\"reviewText\"].apply(lambda x: isinstance(x, str))]"
      ],
      "metadata": {
        "id": "6xStE87W1pJK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = df[\"reviewText\"].tolist()\n",
        "labels = df[\"overall\"].tolist()\n"
      ],
      "metadata": {
        "id": "UNb6A1R71rvE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "encoded_inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cON3iQg4V40",
        "outputId": "e756227d-8555-46f9-a264-6259df2001d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
        "dataset = TensorDataset(encoded_inputs['input_ids'], encoded_inputs['attention_mask'], labels)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "eval_size = len(dataset) - train_size\n",
        "train_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n"
      ],
      "metadata": {
        "id": "ZUrqkp3E4eOO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "c8MrMsNBDvaC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=1).to(device)\n",
        "optimizer = torch.optim.AdamW(bert_model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c3LCKSM9Bui",
        "outputId": "f40686cb-22b1-4701-edf9-bc64973df751"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    bert_model.train()\n",
        "    total_train_loss = 0.0\n",
        "    num_train_batches = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, label = [t.to(device) for t in batch]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask, labels=label)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "        num_train_batches += 1\n",
        "    avg_train_loss = total_train_loss / num_train_batches\n",
        "\n",
        "    # Evaluation\n",
        "    bert_model.eval()\n",
        "    total_eval_loss = 0.0\n",
        "    num_eval_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in eval_loader:\n",
        "            input_ids, attention_mask, label = [t.to(device) for t in batch]\n",
        "            outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask, labels=label)\n",
        "            total_eval_loss += outputs.loss.item()\n",
        "            num_eval_batches += 1\n",
        "    avg_eval_loss = total_eval_loss / num_eval_batches\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Evaluation Loss: {avg_eval_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld1p2LS89JBx",
        "outputId": "dc080f75-d32b-4034-bc51-25616c553a3a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Training Loss: 0.0668, Evaluation Loss: 0.0496\n",
            "Epoch [2/3], Training Loss: 0.0495, Evaluation Loss: 0.0532\n",
            "Epoch [3/3], Training Loss: 0.0397, Evaluation Loss: 0.0396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \"I dont like it\"\n",
        "\n",
        "tokenized_review = tokenizer(review_text, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "input_ids = tokenized_review['input_ids'].to(device)\n",
        "attention_mask = tokenized_review['attention_mask'].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    bert_model.eval()\n",
        "    outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    predicted_rating = outputs.logits.item()\n",
        "\n",
        "print(f\"Predicted rating: {predicted_rating:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG-_ggUr9O4b",
        "outputId": "8a00970f-c202-42c6-ff03-07b571ce19e2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating: 2.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vf-OHl_WHsTr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}